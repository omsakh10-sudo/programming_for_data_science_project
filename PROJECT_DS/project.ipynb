{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463d8358",
   "metadata": {},
   "source": [
    "# Programming for Data Science\n",
    "\n",
    "## Project Title: Book Price Tracker\n",
    "\n",
    "**Students:** Salah aldeen - 202111136 \\\\ Rashed Alfayez -202210706\n",
    "\n",
    "\n",
    "\n",
    "### Project Summary \n",
    "This project builds a complete web-data pipeline: collecting book data from a website using web scraping and crawling, storing it as JSON, accelerating data collection with multithreading, and performing data manipulation & analysis using Pandas. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c9c49",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data Source\n",
    "**Website:** Books to Scrape (educational website designed for scraping practice)\n",
    "\n",
    "**Collected Fields:**\n",
    "- Title\n",
    "- Price\n",
    "- Rating (1–5)\n",
    "- `In Stock?` (True/False)\n",
    "- Product link\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9cbf0",
   "metadata": {},
   "source": [
    "## 2) Tools & Libraries\n",
    "- **requests**: send HTTP requests to fetch web pages\n",
    "- **BeautifulSoup (bs4)**: parse HTML and extract data\n",
    "- **json**: read/write JSON files\n",
    "- **concurrent.futures (ThreadPoolExecutor)**: multithreading for faster crawling\n",
    "- **Pandas**: data cleaning, filtering, grouping, analysis, exporting results\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b9a1f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220efde",
   "metadata": {},
   "source": [
    "Create project folders and define file paths data,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "2782568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "RAW_JSON_PATH = os.path.join(DATA_DIR, \"raw_books.json\")\n",
    "CLEAN_JSON_PATH = os.path.join(DATA_DIR, \"clean_books.json\")\n",
    "\n",
    "BASE_URL = \"https://books.toscrape.com/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b05c4",
   "metadata": {},
   "source": [
    "## 3) JSON\n",
    " Save/Load datasets in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f0484bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_json(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5127a",
   "metadata": {},
   "source": [
    "## 4) Web Scraping\n",
    "### What is Web Scraping?\n",
    "Web scraping is the process of extracting structured information from HTML web pages.\n",
    "\n",
    "### How it is implemented here\n",
    "- Fetch the page HTML using `requests.get()`.\n",
    "- Convert HTML text into a parseable structure using **BeautifulSoup**.\n",
    "- Identify each book entry using the HTML pattern:  \n",
    "  `article.product_pod`\n",
    "- Extract fields:\n",
    "  - **title** from the `<a title=\"...\">` \n",
    "  - **price** from `<p class=\"price_color\">`\n",
    "  - **rating** from star-rating class (`star-rating Three`)\n",
    "  - **availability** from `<p class=\"instock availability\">`\n",
    "  - **link** from `href`, converted to a full URL\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb0b69",
   "metadata": {},
   "source": [
    "test request to make sure the website is reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "bf524a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Length: 51294\n",
      "First 120 chars:\n",
      " <!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get(BASE_URL, headers=headers, timeout=30)\n",
    "print(\"Status:\", resp.status_code)\n",
    "print(\"Length:\", len(resp.text))\n",
    "print(\"First 120 chars:\\n\", resp.text[:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5490f",
   "metadata": {},
   "source": [
    " **Parse HTML and Locate Book Blocks**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "214af89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "Number of books on this page: 20\n",
      "<article class=\"product_pod\">\n",
      " <div class=\"image_container\">\n",
      "  <a href=\"catalogue/a-light-in-the-attic_1000/index.html\">\n",
      "   <img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/>\n",
      "  </a>\n",
      " </div>\n",
      " <p class=\"star-rating Three\">\n",
      "  <i class=\"icon-star\">\n",
      "  </i>\n",
      "  <i class=\"icon-star\">\n",
      "  </i>\n",
      "  <i class=\"icon-star\">\n",
      "  </i>\n",
      "  <i class=\"icon-star\">\n",
      "  </i>\n",
      "  <i class=\"icon-star\">\n",
      "  </i>\n",
      " </p>\n",
      " <h3>\n",
      "  <a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">\n",
      "   A Light in the ...\n",
      "  </a>\n",
      " </h3>\n",
      " <div class=\"product_price\">\n",
      "  <p class=\"price_color\">\n",
      "   Â£51.77\n",
      "  </p>\n",
      "  <p class=\"instock availability\">\n",
      "   <i class=\"icon-ok\">\n",
      "   </i>\n",
      "   In stock\n",
      "  </p>\n",
      "  <form>\n",
      "   <button class=\"btn btn-primary btn-block\" data-loading-\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "print(type(soup))\n",
    "books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "print(\"Number of books on this page:\", len(books))\n",
    "\n",
    "first_book = books[0]\n",
    "print(first_book.prettify()[:800])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344fcb15",
   "metadata": {},
   "source": [
    "Extract title, price, rating, stock status, and link from one book block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8b990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'A Light in the Attic',\n",
       " 'price': 51.77,\n",
       " 'rating': 3,\n",
       " 'In Stock?': True,\n",
       " 'link': 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'}"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_book(article):\n",
    "    # 1) title + link\n",
    "    a_tag = article.find(\"h3\").find(\"a\")\n",
    "    title = a_tag.get(\"title\", \"\").strip()\n",
    "    relative_link = a_tag.get(\"href\", \"\").strip()\n",
    "    full_link = urljoin(BASE_URL, relative_link)\n",
    "\n",
    "    # 2) price\n",
    "    price_text = article.find(\"p\", class_=\"price_color\").get_text(strip=True)\n",
    "    price_text = price_text.replace(\"Â\", \"\").replace(\"£\", \"\").strip()  \n",
    "    price = float(price_text)\n",
    "\n",
    "    # 3) availability\n",
    "    availability_text = article.find(\"p\", class_=\"instock availability\").get_text(\" \", strip=True)\n",
    "    availability = \"In stock\" in availability_text\n",
    "\n",
    "    # 4) rating \n",
    "    rating_tag = article.find(\"p\", class_=\"star-rating\")\n",
    "    rating_classes = rating_tag.get(\"class\", [])\n",
    "    rating_word = [c for c in rating_classes if c != \"star-rating\"][0]\n",
    "    rating_map = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "    rating = rating_map.get(rating_word, None)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"price\": price,\n",
    "        \"rating\": rating,\n",
    "        \"In Stock?\": availability,\n",
    "        \"link\": full_link\n",
    "    }\n",
    "    #test \n",
    "sample = parse_book(first_book)\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "116df087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed books: 20\n",
      "Saved to: c:\\Users\\Hp\\Desktop\\PROJECT_DS\\data\\raw_books.json\n"
     ]
    }
   ],
   "source": [
    "page_books = [parse_book(b) for b in books]\n",
    "print(\"Parsed books:\", len(page_books))\n",
    "\n",
    "save_json(page_books, RAW_JSON_PATH)\n",
    "print(\"Saved to:\", RAW_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93585e51",
   "metadata": {},
   "source": [
    "## 6) Web Crawling\n",
    "### What is Web Crawling?\n",
    "Navigating multiple pages to collect a complete dataset.\n",
    "\n",
    "\n",
    "### How it is implemented here\n",
    "- Read total pages from the text like: Page 1 of 50\n",
    "- Build page URLs using `build_page_url(page_number)`\n",
    "- Loop from page 1 to last page:\n",
    "  - fetch page HTML\n",
    "  - extract all `article.product_pod`\n",
    "  - parse each book using `parse_book`\n",
    "- Save the full raw dataset into `raw_books.json`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee09cf",
   "metadata": {},
   "source": [
    "function to fetch any page and return BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5a2c100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, headers=headers, timeout=30)\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        raise Exception(f\"Request failed! Status={r.status_code} for URL: {url}\")\n",
    "    \n",
    "    return BeautifulSoup(r.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cc967",
   "metadata": {},
   "source": [
    " Read the total number of pages from the website \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d70352ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page text: Page 1 of 50\n",
      "Total pages: 50\n"
     ]
    }
   ],
   "source": [
    "home_soup = get_soup(BASE_URL)\n",
    "current_text = home_soup.find(\"li\", class_=\"current\").get_text(\" \", strip=True)\n",
    "print(\"Page text:\", current_text)\n",
    "total_pages = int(current_text.split(\"of\")[-1].strip())\n",
    "print(\"Total pages:\", total_pages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61c8b6",
   "metadata": {},
   "source": [
    "Build the correct URL for each page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9d15bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/\n",
      "https://books.toscrape.com/catalogue/page-2.html\n",
      "https://books.toscrape.com/catalogue/page-50.html\n"
     ]
    }
   ],
   "source": [
    "def build_page_url(page_number):\n",
    "    if page_number == 1:\n",
    "        return BASE_URL\n",
    "    return urljoin(BASE_URL, f\"catalogue/page-{page_number}.html\")\n",
    "\n",
    "# test\n",
    "print(build_page_url(1))\n",
    "print(build_page_url(2))\n",
    "print(build_page_url(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541bccbb",
   "metadata": {},
   "source": [
    "Crawl all pages sequentially and measure the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2ba45218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1/50 -> 20 books | Total so far: 20\n",
      "Page 2/50 -> 20 books | Total so far: 40\n",
      "Page 3/50 -> 20 books | Total so far: 60\n",
      "Page 4/50 -> 20 books | Total so far: 80\n",
      "Page 5/50 -> 20 books | Total so far: 100\n",
      "Page 6/50 -> 20 books | Total so far: 120\n",
      "Page 7/50 -> 20 books | Total so far: 140\n",
      "Page 8/50 -> 20 books | Total so far: 160\n",
      "Page 9/50 -> 20 books | Total so far: 180\n",
      "Page 10/50 -> 20 books | Total so far: 200\n",
      "Page 11/50 -> 20 books | Total so far: 220\n",
      "Page 12/50 -> 20 books | Total so far: 240\n",
      "Page 13/50 -> 20 books | Total so far: 260\n",
      "Page 14/50 -> 20 books | Total so far: 280\n",
      "Page 15/50 -> 20 books | Total so far: 300\n",
      "Page 16/50 -> 20 books | Total so far: 320\n",
      "Page 17/50 -> 20 books | Total so far: 340\n",
      "Page 18/50 -> 20 books | Total so far: 360\n",
      "Page 19/50 -> 20 books | Total so far: 380\n",
      "Page 20/50 -> 20 books | Total so far: 400\n",
      "Page 21/50 -> 20 books | Total so far: 420\n",
      "Page 22/50 -> 20 books | Total so far: 440\n",
      "Page 23/50 -> 20 books | Total so far: 460\n",
      "Page 24/50 -> 20 books | Total so far: 480\n",
      "Page 25/50 -> 20 books | Total so far: 500\n",
      "Page 26/50 -> 20 books | Total so far: 520\n",
      "Page 27/50 -> 20 books | Total so far: 540\n",
      "Page 28/50 -> 20 books | Total so far: 560\n",
      "Page 29/50 -> 20 books | Total so far: 580\n",
      "Page 30/50 -> 20 books | Total so far: 600\n",
      "Page 31/50 -> 20 books | Total so far: 620\n",
      "Page 32/50 -> 20 books | Total so far: 640\n",
      "Page 33/50 -> 20 books | Total so far: 660\n",
      "Page 34/50 -> 20 books | Total so far: 680\n",
      "Page 35/50 -> 20 books | Total so far: 700\n",
      "Page 36/50 -> 20 books | Total so far: 720\n",
      "Page 37/50 -> 20 books | Total so far: 740\n",
      "Page 38/50 -> 20 books | Total so far: 760\n",
      "Page 39/50 -> 20 books | Total so far: 780\n",
      "Page 40/50 -> 20 books | Total so far: 800\n",
      "Page 41/50 -> 20 books | Total so far: 820\n",
      "Page 42/50 -> 20 books | Total so far: 840\n",
      "Page 43/50 -> 20 books | Total so far: 860\n",
      "Page 44/50 -> 20 books | Total so far: 880\n",
      "Page 45/50 -> 20 books | Total so far: 900\n",
      "Page 46/50 -> 20 books | Total so far: 920\n",
      "Page 47/50 -> 20 books | Total so far: 940\n",
      "Page 48/50 -> 20 books | Total so far: 960\n",
      "Page 49/50 -> 20 books | Total so far: 980\n",
      "Page 50/50 -> 20 books | Total so far: 1000\n",
      "DONE. Total books collected: 1000\n",
      "Time taken (Not Threaded): 48.45 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "all_books = []\n",
    "\n",
    "for page in range(1, total_pages + 1):\n",
    "    page_url = build_page_url(page)\n",
    "    soup_page = get_soup(page_url)\n",
    "    \n",
    "    articles = soup_page.find_all(\"article\", class_=\"product_pod\")\n",
    "    page_data = [parse_book(a) for a in articles]\n",
    "    \n",
    "    all_books.extend(page_data)\n",
    "    print(f\"Page {page}/{total_pages} -> {len(page_data)} books | Total so far: {len(all_books)}\")\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(\"DONE. Total books collected:\", len(all_books))\n",
    "print(f\"Time taken (Not Threaded): {end - start:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0d440daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw dataset to: c:\\Users\\Hp\\Desktop\\PROJECT_DS\\data\\raw_books.json\n"
     ]
    }
   ],
   "source": [
    "save_json(all_books, RAW_JSON_PATH)\n",
    "print(\"Saved raw dataset to:\", RAW_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c59e4",
   "metadata": {},
   "source": [
    "## 7) Multithreading\n",
    "### Why multithreading?\n",
    "Crawling many pages sequentially can be slow because each HTTP request waits for a network response.  \n",
    "Multithreading allows multiple page requests to run in parallel to reduce total runtime.\n",
    "\n",
    "### Implementation approach\n",
    "- Use `ThreadPoolExecutor` with a chosen number of worker threads.\n",
    "- Submit one task per page (fetch + parse page).\n",
    "- Collect results as tasks complete.\n",
    "- Combine all book records into one dataset.\n",
    "\n",
    "**What we print in the notebook:**\n",
    "- `Time taken (Not Threaded): ... seconds`\n",
    "- `Time taken (threaded): ... seconds`\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ff3ca6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc781c",
   "metadata": {},
   "source": [
    "function that scrapes one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "c2f27e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_books(page_number):\n",
    "   \n",
    "    try:\n",
    "        page_url = build_page_url(page_number)\n",
    "        soup_page = get_soup(page_url)\n",
    "        articles = soup_page.find_all(\"article\", class_=\"product_pod\")\n",
    "        return [parse_book(a) for a in articles]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Page {page_number}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b93599",
   "metadata": {},
   "source": [
    "Crawl pages in parallel using ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e90a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished page 8 -> 20 books | Total: 20\n",
      "Finished page 1 -> 20 books | Total: 40\n",
      "Finished page 5 -> 20 books | Total: 60\n",
      "Finished page 4 -> 20 books | Total: 80\n",
      "Finished page 3 -> 20 books | Total: 100\n",
      "Finished page 10 -> 20 books | Total: 120\n",
      "Finished page 2 -> 20 books | Total: 140\n",
      "Finished page 7 -> 20 books | Total: 160\n",
      "Finished page 6 -> 20 books | Total: 180\n",
      "Finished page 9 -> 20 books | Total: 200\n",
      "Finished page 15 -> 20 books | Total: 220\n",
      "Finished page 13 -> 20 books | Total: 240\n",
      "Finished page 20 -> 20 books | Total: 260\n",
      "Finished page 12 -> 20 books | Total: 280\n",
      "Finished page 14 -> 20 books | Total: 300\n",
      "Finished page 17 -> 20 books | Total: 320\n",
      "Finished page 19 -> 20 books | Total: 340\n",
      "Finished page 16 -> 20 books | Total: 360\n",
      "Finished page 11 -> 20 books | Total: 380\n",
      "Finished page 18 -> 20 books | Total: 400\n",
      "Finished page 21 -> 20 books | Total: 420\n",
      "Finished page 26 -> 20 books | Total: 440\n",
      "Finished page 28 -> 20 books | Total: 460\n",
      "Finished page 22 -> 20 books | Total: 480\n",
      "Finished page 30 -> 20 books | Total: 500\n",
      "Finished page 24 -> 20 books | Total: 520\n",
      "Finished page 23 -> 20 books | Total: 540\n",
      "Finished page 27 -> 20 books | Total: 560\n",
      "Finished page 29 -> 20 books | Total: 580\n",
      "Finished page 25 -> 20 books | Total: 600\n",
      "Finished page 40 -> 20 books | Total: 620\n",
      "Finished page 38 -> 20 books | Total: 640\n",
      "Finished page 35 -> 20 books | Total: 660\n",
      "Finished page 32 -> 20 books | Total: 680\n",
      "Finished page 34 -> 20 books | Total: 700\n",
      "Finished page 31 -> 20 books | Total: 720\n",
      "Finished page 33 -> 20 books | Total: 740\n",
      "Finished page 37 -> 20 books | Total: 760\n",
      "Finished page 39 -> 20 books | Total: 780\n",
      "Finished page 36 -> 20 books | Total: 800\n",
      "Finished page 41 -> 20 books | Total: 820\n",
      "Finished page 48 -> 20 books | Total: 840\n",
      "Finished page 45 -> 20 books | Total: 860\n",
      "Finished page 42 -> 20 books | Total: 880\n",
      "Finished page 49 -> 20 books | Total: 900\n",
      "Finished page 43 -> 20 books | Total: 920\n",
      "Finished page 44 -> 20 books | Total: 940\n",
      "Finished page 47 -> 20 books | Total: 960\n",
      "Finished page 50 -> 20 books | Total: 980\n",
      "Finished page 46 -> 20 books | Total: 1000\n",
      "\n",
      "Threaded crawling DONE. Total books: 1000\n",
      "Time taken (threaded): (7.73) seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "all_books_threaded = []\n",
    "\n",
    "max_workers = 10 \n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = {executor.submit(fetch_page_books, p): p for p in range(1, total_pages + 1)}\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        page_num = futures[future]\n",
    "        page_data = future.result()\n",
    "        all_books_threaded.extend(page_data)\n",
    "        print(f\"Finished page {page_num} -> {len(page_data)} books | Total: {len(all_books_threaded)}\")\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"\\nThreaded crawling DONE. Total books: {len(all_books_threaded)}\")\n",
    "print(f\"Time taken (threaded): ({end - start:.2f}) seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217b1ab",
   "metadata": {},
   "source": [
    "Save the multithreaded dataset into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "666c7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved threaded dataset to: c:\\Users\\Hp\\Desktop\\PROJECT_DS\\data\\raw_books_threaded.json\n"
     ]
    }
   ],
   "source": [
    "RAW_JSON_THREADED_PATH = os.path.join(DATA_DIR, \"raw_books_threaded.json\")\n",
    "save_json(all_books_threaded, RAW_JSON_THREADED_PATH)\n",
    "print(\"Saved threaded dataset to:\", RAW_JSON_THREADED_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ea310",
   "metadata": {},
   "source": [
    "## 8) Pandas \n",
    "\n",
    "### Loading & Cleaning\n",
    "- Load the JSON dataset into a Pandas DataFrame\n",
    "- Check dataset shape and data types (`df.info()` / `df.describe()`)\n",
    "- Check missing values (`df.isnull().sum()`)\n",
    "- Fill missing values:\n",
    "  - `price` filled with mean\n",
    "  - `rating` filled with median then convert to int\n",
    "- Grouping:\n",
    "  - mean price by rating\n",
    "  - min/max/mean/median price by rating\n",
    "- Filtering:\n",
    "  - create a subset for NOT in stock (`In Stock? == False`)\n",
    "  - create best deals: in stock + rating >= 4 + price < 30\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebbe6a",
   "metadata": {},
   "source": [
    "Load the JSON dataset into a Pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "33d2f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>In Stock?</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Her Wake</td>\n",
       "      <td>12.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/in-her-wake_980/ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How Music Works</td>\n",
       "      <td>37.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/how-music-works_979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foolproof Preserving: A Guide to Small Batch J...</td>\n",
       "      <td>30.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/foolproof-preservin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Me (Paris Nights #2)</td>\n",
       "      <td>25.27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/chase-me-paris-nigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Dust</td>\n",
       "      <td>34.53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/black-dust_976/inde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  price  rating  \\\n",
       "0                                        In Her Wake  12.84     1.0   \n",
       "1                                    How Music Works  37.32     2.0   \n",
       "2  Foolproof Preserving: A Guide to Small Batch J...  30.52     3.0   \n",
       "3                         Chase Me (Paris Nights #2)  25.27     5.0   \n",
       "4                                         Black Dust  34.53     5.0   \n",
       "\n",
       "   In Stock?                                               link  \n",
       "0       True  https://books.toscrape.com/in-her-wake_980/ind...  \n",
       "1       True  https://books.toscrape.com/how-music-works_979...  \n",
       "2       True  https://books.toscrape.com/foolproof-preservin...  \n",
       "3       True  https://books.toscrape.com/chase-me-paris-nigh...  \n",
       "4       True  https://books.toscrape.com/black-dust_976/inde...  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_json(RAW_JSON_THREADED_PATH)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Dataset shape:\",df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76a8a1",
   "metadata": {},
   "source": [
    "Check dataset shape and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "0572033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   title      1000 non-null   object \n",
      " 1   price      976 non-null    float64\n",
      " 2   rating     992 non-null    float64\n",
      " 3   In Stock?  1000 non-null   bool   \n",
      " 4   link       1000 non-null   object \n",
      "dtypes: bool(1), float64(2), object(2)\n",
      "memory usage: 32.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>976.000000</td>\n",
       "      <td>992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.102059</td>\n",
       "      <td>2.925403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.470956</td>\n",
       "      <td>1.434925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.095000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.110000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.535000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.990000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price      rating\n",
       "count  976.000000  992.000000\n",
       "mean    35.102059    2.925403\n",
       "std     14.470956    1.434925\n",
       "min     10.000000    1.000000\n",
       "25%     22.095000    2.000000\n",
       "50%     36.110000    3.000000\n",
       "75%     47.535000    4.000000\n",
       "max     59.990000    5.000000"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbbc9d",
   "metadata": {},
   "source": [
    "Check missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "342b1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null Values are:\n",
      "  title         0\n",
      "price        24\n",
      "rating        8\n",
      "In Stock?     0\n",
      "link          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The null Values are:\\n \",df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8323a3",
   "metadata": {},
   "source": [
    "Fill missing values for price and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9d135327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean price is: 35.1020594262295\n",
      "_________________________________________________________\n",
      "The median rating is: 3.0\n",
      "_________________________________________________________\n",
      "The null Values are:\n",
      "  title        0\n",
      "price        0\n",
      "rating       0\n",
      "In Stock?    0\n",
      "link         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "price_mean = df[\"price\"].mean()\n",
    "print(\"The mean price is:\", price_mean)\n",
    "df[\"price\"] = df[\"price\"].fillna(price_mean)\n",
    "print(\"_________________________________________________________\")\n",
    "\n",
    "rating_median = df[\"rating\"].median()\n",
    "print(\"The median rating is:\", rating_median)\n",
    "df[\"rating\"] = df[\"rating\"].fillna(rating_median)\n",
    "print(\"_________________________________________________________\")\n",
    "\n",
    "\n",
    "print(\"The null Values are:\\n \",df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528141e8",
   "metadata": {},
   "source": [
    "converting rating from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "73df9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999    5\n",
       "565    5\n",
       "611    5\n",
       "610    5\n",
       "601    5\n",
       "      ..\n",
       "683    1\n",
       "136    1\n",
       "137    1\n",
       "661    1\n",
       "0      1\n",
       "Name: rating, Length: 1000, dtype: int32"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"] = df[\"rating\"].astype(int)\n",
    "df[\"rating\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5013a3",
   "metadata": {},
   "source": [
    "Grouping: average price by rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "4bf86c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "1    34.481671\n",
      "2    35.004810\n",
      "3    34.281062\n",
      "4    36.285889\n",
      "5    35.724771\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#grouping\n",
    "avg_price_by_rating = df.groupby(\"rating\")[\"price\"].mean()\n",
    "print(avg_price_by_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd4ea7",
   "metadata": {},
   "source": [
    "min/max/mean/median price by rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d649c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.40</td>\n",
       "      <td>59.64</td>\n",
       "      <td>34.481671</td>\n",
       "      <td>35.102059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.02</td>\n",
       "      <td>59.95</td>\n",
       "      <td>35.004810</td>\n",
       "      <td>36.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.16</td>\n",
       "      <td>59.99</td>\n",
       "      <td>34.281062</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.01</td>\n",
       "      <td>59.45</td>\n",
       "      <td>36.285889</td>\n",
       "      <td>37.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>59.92</td>\n",
       "      <td>35.724771</td>\n",
       "      <td>36.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min    max       mean     median\n",
       "rating                                    \n",
       "1       10.40  59.64  34.481671  35.102059\n",
       "2       10.02  59.95  35.004810  36.170000\n",
       "3       10.16  59.99  34.281062  33.290000\n",
       "4       10.01  59.45  36.285889  37.510000\n",
       "5       10.00  59.92  35.724771  36.830000"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_rating = df.groupby(\"rating\")[\"price\"].agg([ \"min\", \"max\", \"mean\", \"median\"])\n",
    "group_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af26481",
   "metadata": {},
   "source": [
    "Books are NOT in stock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "7a1cff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in stock: (9, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>In Stock?</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Catastrophic Happiness: Finding Joy in Childho...</td>\n",
       "      <td>37.350000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/catastrophic-happin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Boy Meets Boy</td>\n",
       "      <td>21.120000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/boy-meets-boy_134/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Big Little Lies</td>\n",
       "      <td>35.102059</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/big-little-lies_129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Beautiful Creatures (Caster Chronicles #1)</td>\n",
       "      <td>21.550000</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/beautiful-creatures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Are We There Yet?</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/are-we-there-yet_12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>43.380000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/beyond-good-and-evi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Paper Girls, Vol. 1 (Paper Girls #1-5)</td>\n",
       "      <td>21.710000</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/paper-girls-vol-1-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>When I'm Gone</td>\n",
       "      <td>51.960000</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/when-im-gone_95/ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>The Wicked + The Divine, Vol. 1: The Faust Act...</td>\n",
       "      <td>36.520000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>https://books.toscrape.com/the-wicked-the-divi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title      price  rating  \\\n",
       "882  Catastrophic Happiness: Finding Joy in Childho...  37.350000       2   \n",
       "886                                      Boy Meets Boy  21.120000       3   \n",
       "891                                    Big Little Lies  35.102059       1   \n",
       "895         Beautiful Creatures (Caster Chronicles #1)  21.550000       5   \n",
       "898                                  Are We There Yet?  10.660000       3   \n",
       "914                               Beyond Good and Evil  43.380000       1   \n",
       "936             Paper Girls, Vol. 1 (Paper Girls #1-5)  21.710000       4   \n",
       "945                                      When I'm Gone  51.960000       3   \n",
       "954  The Wicked + The Divine, Vol. 1: The Faust Act...  36.520000       2   \n",
       "\n",
       "     In Stock?                                               link  \n",
       "882      False  https://books.toscrape.com/catastrophic-happin...  \n",
       "886      False  https://books.toscrape.com/boy-meets-boy_134/i...  \n",
       "891      False  https://books.toscrape.com/big-little-lies_129...  \n",
       "895      False  https://books.toscrape.com/beautiful-creatures...  \n",
       "898      False  https://books.toscrape.com/are-we-there-yet_12...  \n",
       "914      False  https://books.toscrape.com/beyond-good-and-evi...  \n",
       "936      False  https://books.toscrape.com/paper-girls-vol-1-p...  \n",
       "945      False  https://books.toscrape.com/when-im-gone_95/ind...  \n",
       "954      False  https://books.toscrape.com/the-wicked-the-divi...  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_instock = df[df[\"In Stock?\"] == False].copy()\n",
    "print(\"Not in stock:\", df_instock.shape)\n",
    "df_instock\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9390bb5",
   "metadata": {},
   "source": [
    "create best deals in stock + high rating + low price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "75e386db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best deals: (135, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>In Stock?</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>An Abundance of Katherines</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/an-abundance-of-kat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>The Origin of Species</td>\n",
       "      <td>10.01</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/the-origin-of-speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>History of Beauty</td>\n",
       "      <td>10.29</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/history-of-beauty_5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>NaNo What Now? Finding your editing process, r...</td>\n",
       "      <td>10.41</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/nano-what-now-findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Green Eggs and Ham (Beginner Books B-16)</td>\n",
       "      <td>10.79</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/green-eggs-and-ham-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>The Power Greens Cookbook: 140 Delicious Super...</td>\n",
       "      <td>11.05</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/the-power-greens-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Dear Mr. Knightley</td>\n",
       "      <td>11.21</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/dear-mr-knightley_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>City of Fallen Angels (The Mortal Instruments #4)</td>\n",
       "      <td>11.23</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/city-of-fallen-ange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>The Darkest Corners</td>\n",
       "      <td>11.33</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/the-darkest-corners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Naturally Lean: 125 Nourishing Gluten-Free, Pl...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>https://books.toscrape.com/naturally-lean-125-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  price  rating  \\\n",
       "618                         An Abundance of Katherines  10.00       5   \n",
       "421                              The Origin of Species  10.01       4   \n",
       "539                                  History of Beauty  10.29       4   \n",
       "574  NaNo What Now? Finding your editing process, r...  10.41       4   \n",
       "835           Green Eggs and Ham (Beginner Books B-16)  10.79       4   \n",
       "590  The Power Greens Cookbook: 140 Delicious Super...  11.05       5   \n",
       "396                                 Dear Mr. Knightley  11.21       5   \n",
       "363  City of Fallen Angels (The Mortal Instruments #4)  11.23       4   \n",
       "621                                The Darkest Corners  11.33       5   \n",
       "501  Naturally Lean: 125 Nourishing Gluten-Free, Pl...  11.38       5   \n",
       "\n",
       "     In Stock?                                               link  \n",
       "618       True  https://books.toscrape.com/an-abundance-of-kat...  \n",
       "421       True  https://books.toscrape.com/the-origin-of-speci...  \n",
       "539       True  https://books.toscrape.com/history-of-beauty_5...  \n",
       "574       True  https://books.toscrape.com/nano-what-now-findi...  \n",
       "835       True  https://books.toscrape.com/green-eggs-and-ham-...  \n",
       "590       True  https://books.toscrape.com/the-power-greens-co...  \n",
       "396       True  https://books.toscrape.com/dear-mr-knightley_6...  \n",
       "363       True  https://books.toscrape.com/city-of-fallen-ange...  \n",
       "621       True  https://books.toscrape.com/the-darkest-corners...  \n",
       "501       True  https://books.toscrape.com/naturally-lean-125-...  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_deals = df[(df[\"In Stock?\"] == True) & (df[\"rating\"] >= 4) & (df[\"price\"] < 30)].copy()\n",
    "print(\"Best deals:\", df_best_deals.shape)\n",
    "df_best_deals.sort_values(by=\"price\").head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed0171",
   "metadata": {},
   "source": [
    "Save cleaned data + outputs (JSON/CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean dataset\n",
    "clean_records = df.to_dict(orient=\"records\")\n",
    "save_json(clean_records, CLEAN_JSON_PATH)\n",
    "CLEAN_CSV_PATH = os.path.join(DATA_DIR, \"clean_books.csv\")\n",
    "df.to_csv(CLEAN_CSV_PATH, index=False)\n",
    "\n",
    "print(\"Saved clean dataset to:\", CLEAN_JSON_PATH)\n",
    "print(\"Saved clean CSV to:\", CLEAN_CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c4e6a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved analysis outputs into outputs/ folder\n"
     ]
    }
   ],
   "source": [
    "group_rating.to_csv(os.path.join(OUTPUT_DIR, \"price_stats_by_rating.csv\"))\n",
    "df_best_deals.to_csv(os.path.join(OUTPUT_DIR, \"best_deals.csv\"), index=False)\n",
    "\n",
    "print(\"Saved analysis outputs into outputs/ folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee0fcb",
   "metadata": {},
   "source": [
    "## 9) Conclusion\n",
    "This project collected book data from a website using web scraping and crawling, saved results as JSON, improved crawling speed using multithreading, and analyzed the final dataset using Pandas (missing values handling, filtering, and grouping). Clean datasets and analysis outputs were exported as JSON/CSV files.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
